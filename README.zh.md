![](https://github.com/user-attachments/assets/e59519f1-c5db-43b0-9cf8-c5981bc4c8d6)

# OmniDocBench

<!-- <p align="center">
  <img src="assets/readme/pdf-extract-kit_logo.png" width="220px" style="vertical-align:middle;">
</p> -->

<!-- <div align="center"> -->

[English](./README.md) | ç®€ä½“ä¸­æ–‡

[[Dataset (ğŸ¤—Hugging Face)]](https://huggingface.co/datasets/opendatalab/OmniDocBench) | [[Dataset (OpenDataLab)]](https://opendatalab.com/OpenDataLab/OmniDocBench)

**OmniDocBench**æ˜¯ä¸€ä¸ªé’ˆå¯¹çœŸå®åœºæ™¯ä¸‹å¤šæ ·æ€§æ–‡æ¡£è§£æè¯„æµ‹é›†ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- **æ–‡æ¡£ç±»å‹å¤šæ ·**ï¼šè¯¥è¯„æµ‹é›†æ¶‰åŠ981ä¸ªPDFé¡µé¢ï¼Œæ¶µç›–9ç§æ–‡æ¡£ç±»å‹ã€4ç§æ’ç‰ˆç±»å‹å’Œ3ç§è¯­è¨€ç±»å‹ã€‚è¦†ç›–é¢å¹¿ï¼ŒåŒ…å«å­¦æœ¯æ–‡çŒ®ã€è´¢æŠ¥ã€æŠ¥çº¸ã€æ•™æã€æ‰‹å†™ç¬”è®°ç­‰ï¼›
- **æ ‡æ³¨ä¿¡æ¯ä¸°å¯Œ**ï¼šåŒ…å«15ä¸ªblockçº§åˆ«ï¼ˆæ–‡æœ¬æ®µè½ã€æ ‡é¢˜ã€è¡¨æ ¼ç­‰ï¼Œæ€»é‡è¶…è¿‡20kï¼‰å’Œ4ä¸ªSpançº§åˆ«ï¼ˆæ–‡æœ¬è¡Œã€è¡Œå†…å…¬å¼ã€è§’æ ‡ç­‰ï¼Œæ€»é‡è¶…è¿‡80kï¼‰çš„æ–‡æ¡£å…ƒç´ çš„**å®šä½ä¿¡æ¯**ï¼Œä»¥åŠæ¯ä¸ªå…ƒç´ åŒºåŸŸçš„**è¯†åˆ«ç»“æœ**ï¼ˆæ–‡æœ¬Textæ ‡æ³¨ï¼Œå…¬å¼LaTeXæ ‡æ³¨ï¼Œè¡¨æ ¼åŒ…å«LaTeXå’ŒHTMLä¸¤ç§ç±»å‹çš„æ ‡æ³¨ï¼‰ã€‚OmniDocBenchè¿˜æä¾›äº†å„ä¸ªæ–‡æ¡£ç»„ä»¶çš„**é˜…è¯»é¡ºåº**çš„æ ‡æ³¨ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨é¡µé¢å’Œblockçº§åˆ«è¿˜åŒ…å«å¤šç§å±æ€§æ ‡ç­¾ï¼Œæ ‡æ³¨äº†5ç§**é¡µé¢å±æ€§æ ‡ç­¾**ã€3ç§**æ–‡æœ¬å±æ€§æ ‡ç­¾**å’Œ6ç§**è¡¨æ ¼å±æ€§æ ‡ç­¾**ã€‚
- **æ ‡æ³¨è´¨é‡é«˜**ï¼šç»è¿‡äººå·¥ç­›é€‰ï¼Œæ™ºèƒ½æ ‡æ³¨ï¼Œäººå·¥æ ‡æ³¨åŠå…¨é‡ä¸“å®¶è´¨æ£€å’Œå¤§æ¨¡å‹è´¨æ£€ï¼Œæ•°æ®è´¨é‡è¾ƒé«˜ã€‚
- **é…å¥—è¯„æµ‹ä»£ç **ï¼šè®¾è®¡ç«¯åˆ°ç«¯è¯„æµ‹åŠå•æ¨¡å—è¯„æµ‹ä»£ç ï¼Œä¿è¯è¯„æµ‹çš„å…¬å¹³æ€§åŠå‡†ç¡®æ€§ã€‚

å¯è¿›è¡Œä»¥ä¸‹å‡ ä¸ªç»´åº¦çš„è¯„æµ‹ï¼š
- ç«¯åˆ°ç«¯è¯„æµ‹ï¼šåŒ…æ‹¬end2endå’Œmd2mdä¸¤ç§è¯„æµ‹æ–¹å¼
- Layoutæ£€æµ‹
- è¡¨æ ¼è¯†åˆ«
- å…¬å¼è¯†åˆ«
- æ–‡æœ¬OCR

ç›®å‰æ”¯æŒçš„metricåŒ…æ‹¬ï¼š
- Normalized Edit Distance
- BLEU
- METEOR
- TEDS
- COCODet (mAP, mAR, etc.)

## è¯„æµ‹é›†ä»‹ç»

è¯¥è¯„æµ‹é›†æ¶‰åŠ981ä¸ªPDFé¡µé¢ï¼Œæ¶µç›–9ç§æ–‡æ¡£ç±»å‹ã€4ç§æ’ç‰ˆç±»å‹å’Œ3ç§è¯­è¨€ç±»å‹ã€‚OmniDocBenchå…·æœ‰ä¸°å¯Œçš„æ ‡æ³¨ï¼ŒåŒ…å«15ä¸ªblockçº§åˆ«çš„æ ‡æ³¨ï¼ˆæ–‡æœ¬æ®µè½ã€æ ‡é¢˜ã€è¡¨æ ¼ç­‰ï¼‰å’Œ4ä¸ªSpançº§åˆ«çš„æ ‡æ³¨ï¼ˆæ–‡æœ¬è¡Œã€è¡Œå†…å…¬å¼ã€è§’æ ‡ç­‰ï¼‰ã€‚æ‰€æœ‰æ–‡æœ¬ç›¸å…³çš„æ ‡æ³¨æ¡†ä¸Šéƒ½åŒ…å«æ–‡æœ¬è¯†åˆ«çš„æ ‡æ³¨ï¼Œå…¬å¼åŒ…å«LaTeXæ ‡æ³¨ï¼Œè¡¨æ ¼åŒ…å«LaTeXå’ŒHTMLä¸¤ç§ç±»å‹çš„æ ‡æ³¨ã€‚OmniDocBenchè¿˜æä¾›äº†å„ä¸ªæ–‡æ¡£ç»„ä»¶çš„é˜…è¯»é¡ºåºçš„æ ‡æ³¨ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨é¡µé¢å’Œblockçº§åˆ«è¿˜åŒ…å«å¤šç§å±æ€§æ ‡ç­¾ï¼Œæ ‡æ³¨äº†5ç§é¡µé¢å±æ€§æ ‡ç­¾ã€3ç§æ–‡æœ¬å±æ€§æ ‡ç­¾å’Œ6ç§è¡¨æ ¼å±æ€§æ ‡ç­¾ã€‚

![](https://github.com/user-attachments/assets/f3e53ba8-bb97-4ca9-b2e7-e2530865aaa9)

<details>
  <summary>è¯„æµ‹é›†çš„æ•°æ®æ ¼å¼</summary>

è¯„æµ‹é›†çš„æ•°æ®æ ¼å¼ä¸ºJSONï¼Œå…¶ç»“æ„å’Œå„ä¸ªå­—æ®µçš„è§£é‡Šå¦‚ä¸‹ï¼š

```json
[{
    "layout_dets": [    // é¡µé¢å…ƒç´ åˆ—è¡¨
        {
            "category_type": "text_block",  // ç±»åˆ«åç§°
            "poly": [
                136.0, // ä½ç½®ä¿¡æ¯ï¼Œåˆ†åˆ«æ˜¯å·¦ä¸Šè§’ã€å³ä¸Šè§’ã€å³ä¸‹è§’ã€å·¦ä¸‹è§’çš„x,yåæ ‡
                781.0,
                340.0,
                781.0,
                340.0,
                806.0,
                136.0,
                806.0
            ],
            "ignore": false,        // æ˜¯å¦åœ¨è¯„æµ‹çš„æ—¶å€™ä¸è€ƒè™‘
            "order": 0,             // é˜…è¯»é¡ºåº
            "anno_id": 0,           // ç‰¹æ®Šçš„æ ‡æ³¨IDï¼Œæ¯ä¸ªlayoutæ¡†å”¯ä¸€
            "text": "xxx",          // å¯é€‰å­—æ®µï¼ŒOCRç»“æœä¼šå†™åœ¨è¿™é‡Œ
            "latex": "$xxx$",       // å¯é€‰å­—æ®µï¼Œformulaå’Œtableçš„LaTeXä¼šå†™åœ¨è¿™é‡Œ
            "html": "xxx",          // å¯é€‰å­—æ®µï¼Œtableçš„HTMLä¼šå†™åœ¨è¿™é‡Œ
            "attribute" {"xxx": "xxx"},         // layoutçš„åˆ†ç±»å±æ€§ï¼Œåæ–‡ä¼šè¯¦ç»†å±•ç¤º
            "line_with_spans:": [   // span levelçš„æ ‡æ³¨æ¡†
                {
                    "category_type": "text_span",
                    "poly": [...],
                    "ignore": false,
                    "text": "xxx",   
                    "latex": "$xxx$",
                 },
                 ...
            ],
            "merge_list": [    // åªæœ‰åŒ…å«mergeå…³ç³»çš„æ ‡æ³¨æ¡†å†…æœ‰è¿™ä¸ªå­—æ®µï¼Œæ˜¯å¦åŒ…å«mergeé€»è¾‘å–å†³äºæ˜¯å¦åŒ…å«å•æ¢è¡Œåˆ†å‰²å°æ®µè½ï¼Œæ¯”å¦‚åˆ—è¡¨ç±»å‹
                {
                    "category_type": "text_block", 
                    "poly": [...],
                    ...   // è·Ÿblockçº§åˆ«æ ‡æ³¨çš„å­—æ®µä¸€è‡´
                    "line_with_spans": [...]
                    ...
                 },
                 ...
            ]
        ...
    ],
    "page_info": {         
        "page_no": 0,            // é¡µç 
        "height": 1684,          // é¡µé¢çš„å®½
        "width": 1200,           // é¡µé¢çš„é«˜
        "image_path": "xx/xx/",  // æ ‡æ³¨çš„é¡µé¢æ–‡ä»¶åç§°
        "page_attribute": {"xxx": "xxx"}     // é¡µé¢çš„å±æ€§æ ‡ç­¾
    },
    "extra": {
        "relation": [ // å…·æœ‰ç›¸å…³å…³ç³»çš„æ ‡æ³¨
            {  
                "source_anno_id": 1,
                "target_anno_id": 2, 
                "relation": "parent_son"  // figure/tableä¸å…¶å¯¹åº”çš„caption/footnoteç±»åˆ«çš„å…³ç³»æ ‡ç­¾
            },
            {  
                "source_anno_id": 5,
                "target_anno_id": 6,
                "relation_type": "truncated"  // æ®µè½å› ä¸ºæ’ç‰ˆåŸå› è¢«æˆªæ–­ï¼Œä¼šæ ‡æ³¨ä¸€ä¸ªæˆªæ–­å…³ç³»æ ‡ç­¾ï¼Œåç»­è¯„æµ‹çš„æ—¶å€™ä¼šæ‹¼æ¥åå†ä½œä¸ºä¸€æ•´ä¸ªæ®µè½è¿›è¡Œè¯„æµ‹
            },
        ]
    }
},
...
]
```

</details>

<details>
  <summary>éªŒè¯é›†ç±»åˆ«</summary>

éªŒè¯é›†ç±»åˆ«åŒ…æ‹¬ï¼š

```
# Blockçº§åˆ«æ ‡æ³¨æ¡†
'title'               # æ ‡é¢˜
'text_block'          # æ®µè½çº§åˆ«çº¯æ–‡æœ¬
'figure',             # å›¾ç‰‡ç±»
'figure_caption',     # å›¾ç‰‡è¯´æ˜ã€æ ‡é¢˜
'figure_footnote',    # å›¾ç‰‡æ³¨é‡Š
'table',              # è¡¨æ ¼ä¸»ä½“
'table_caption',      # è¡¨æ ¼è¯´æ˜å’Œæ ‡é¢˜
'table_footnote',     # è¡¨æ ¼çš„æ³¨é‡Š
'equation_isolated',  # è¡Œé—´å…¬å¼
'equation_caption',   # å…¬å¼åºå·
'header'              # é¡µçœ‰
'footer'              # é¡µè„š  
'page_number'         # é¡µç 
'page_footnote'       # é¡µé¢æ³¨é‡Š
'abandon',            # å…¶ä»–çš„èˆå¼ƒç±»ï¼ˆæ¯”å¦‚é¡µé¢ä¸­é—´çš„ä¸€äº›æ— å…³ä¿¡æ¯ï¼‰
'code_txt',           # ä»£ç å—
'code_txt_caption',   # ä»£ç å—è¯´æ˜
'reference',          # å‚è€ƒæ–‡çŒ®ç±»

# Spançº§åˆ«æ ‡æ³¨æ¡†
'text_span'           # spançº§åˆ«çš„çº¯æ–‡æœ¬
'equation_ignore',    # éœ€è¦å¿½ç•¥çš„å…¬å¼ç±»
'equation_inline',    # è¡Œå†…å…¬å¼ç±»
'footnote_mark',      #æ–‡ç« çš„ä¸Šä¸‹è§’æ ‡
```

</details>

<details>
  <summary>éªŒè¯é›†å±æ€§æ ‡ç­¾</summary>

é¡µé¢åˆ†ç±»å±æ€§åŒ…æ‹¬ï¼š
```
'data_source': #PDFç±»å‹åˆ†ç±»
    academic_literature  # å­¦æœ¯æ–‡çŒ®
    PPT2PDF # PPTè½¬PDF
    book # é»‘ç™½çš„å›¾ä¹¦å’Œæ•™æ
    colorful_textbook # å½©è‰²å›¾æ–‡æ•™æ
    exam_paper # è¯•å·
    note # æ‰‹å†™ç¬”è®°
    magazine # æ‚å¿—
    research_report # ç ”æŠ¥ã€è´¢æŠ¥
    newspaper # æŠ¥çº¸

'language':#è¯­ç§
    en # è‹±æ–‡
    simplified_chinese # ç®€ä½“ä¸­æ–‡
    en_ch_mixed # ä¸­è‹±æ··åˆ

'layout': #é¡µé¢å¸ƒå±€ç±»å‹
    single_column # å•æ 
    double_column # åŒæ 
    three_column # ä¸‰æ 
    1andmore_column # ä¸€æ··å¤šï¼Œå¸¸è§äºæ–‡çŒ®
    other_layout # å…¶ä»–

'watermark'ï¼š # æ˜¯å¦åŒ…å«æ°´å°
    true  
    false

'fuzzy_scan': # æ˜¯å¦æ¨¡ç³Šæ‰«æ
    true  
    false

'colorful_backgroud': # æ˜¯å¦åŒ…å«å½©è‰²èƒŒæ™¯ï¼Œéœ€è¦å‚ä¸è¯†åˆ«çš„å†…å®¹çš„åº•è‰²åŒ…å«ä¸¤ä¸ªä»¥ä¸Š
    true  
    false
```

æ ‡æ³¨æ¡†çº§åˆ«å±æ€§-è¡¨æ ¼ç›¸å…³å±æ€§:

```
'table_layout': # è¡¨æ ¼çš„æ–¹å‘
    vertical #ç«–ç‰ˆè¡¨æ ¼
    horizontal #æ¨ªç‰ˆè¡¨æ ¼

'with_span': # åˆå¹¶å•å…ƒæ ¼
    False
    True

'line':# è¡¨æ ¼çš„çº¿æ¡†
    full_line # å…¨çº¿æ¡†
    less_line # æ¼çº¿æ¡†
    fewer_line # ä¸‰çº¿æ¡† 
    wireless_line # æ— çº¿æ¡†

'language': #è¡¨æ ¼çš„è¯­ç§
    table_en  # è‹±æ–‡è¡¨æ ¼
    table_simplified_chinese  #ä¸­æ–‡ç®€ä½“è¡¨æ ¼
    table_en_ch_mixed  #ä¸­è‹±æ··åˆè¡¨æ ¼

'include_equation': # è¡¨æ ¼æ˜¯å¦åŒ…å«å…¬å¼
    False
    True

'include_backgroud': # è¡¨æ ¼æ˜¯å¦åŒ…å«åº•è‰²
    False
    True

'table_vertical' # è¡¨æ ¼æ˜¯å¦æ—‹è½¬90åº¦æˆ–270åº¦
    False
    True
```

æ ‡æ³¨æ¡†çº§åˆ«å±æ€§-æ–‡æœ¬æ®µè½ç›¸å…³å±æ€§: 
```
'text_language': # æ–‡æœ¬çš„æ®µè½å†…è¯­ç§
    text_en  # è‹±æ–‡
    text_simplified_chinese #ç®€ä½“ä¸­æ–‡
    text_en_ch_mixed  #ä¸­è‹±æ··åˆ

'text_background':  #æ–‡æœ¬çš„èƒŒæ™¯è‰²
    white # é»˜è®¤å€¼ï¼Œç™½è‰²èƒŒæ™¯
    single_colored # é™¤ç™½è‰²å¤–çš„å•èƒŒæ™¯è‰²
    multi_colored  # æ··åˆèƒŒæ™¯è‰²

'text_rotate': # æ–‡æœ¬çš„æ®µè½å†…æ–‡å­—æ—‹è½¬åˆ†ç±»
    normal # é»˜è®¤å€¼ï¼Œæ¨ªå‘æ–‡æœ¬ï¼Œæ²¡æœ‰æ—‹è½¬
    rotate90  # æ—‹è½¬è§’åº¦ï¼Œé¡ºæ—¶é’ˆæ—‹è½¬90åº¦
    rotate180 # é¡ºæ—¶é’ˆæ—‹è½¬180åº¦
    rotate270 # é¡ºæ—¶é’ˆæ—‹è½¬270åº¦
    horizontal # æ–‡å­—æ˜¯æ­£å¸¸çš„ï¼Œæ’ç‰ˆæ˜¯ç«–å‹æ–‡æœ¬
```

æ ‡æ³¨æ¡†çº§åˆ«å±æ€§-å…¬å¼ç›¸å…³å±æ€§: 
```
'formula_type': #å…¬å¼ç±»å‹
    print  # æ‰“å°ä½“
    handwriting # æ‰‹å†™ä½“
```

</details>


## è¯„æµ‹

OmniDocBenchå¼€å‘äº†ä¸€å¥—åŸºäºæ–‡æ¡£ç»„ä»¶æ‹†åˆ†å’ŒåŒ¹é…çš„è¯„æµ‹æ–¹æ³•ï¼Œå¯¹æ–‡æœ¬ã€è¡¨æ ¼ã€å…¬å¼ã€é˜…è¯»é¡ºåºè¿™å››å¤§æ¨¡å—åˆ†åˆ«æä¾›äº†å¯¹åº”çš„æŒ‡æ ‡è®¡ç®—ï¼Œè¯„æµ‹ç»“æœé™¤äº†æ•´ä½“çš„ç²¾åº¦ç»“æœä»¥å¤–ï¼Œè¿˜æä¾›äº†åˆ†é¡µé¢ä»¥åŠåˆ†å±æ€§çš„ç²¾ç»†åŒ–è¯„æµ‹ç»“æœï¼Œç²¾å‡†å®šä½æ¨¡å‹æ–‡æ¡£è§£æçš„ç—›ç‚¹é—®é¢˜ã€‚

![](https://github.com/user-attachments/assets/95c88aaa-75dc-432e-891e-17a7d73e024a)

### ç¯å¢ƒé…ç½®å’Œè¿è¡Œ

ç¯å¢ƒé…ç½®åªéœ€è¦åœ¨è¯¥é¡¹ç›®ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤å³å¯ï¼š

```bash
conda create -n omnidocbench python=3.8
conda activate omnidocbench
pip install -r requirements.txt
```

æ‰€æœ‰çš„è¯„æµ‹çš„è¾“å…¥éƒ½æ˜¯é€šè¿‡configæ–‡ä»¶è¿›è¡Œé…ç½®çš„ï¼Œæˆ‘ä»¬åœ¨[configs](./configs)è·¯å¾„ä¸‹æä¾›äº†å„ä¸ªä»»åŠ¡çš„æ¨¡æ¿ï¼Œå¹¶ä¸”åœ¨æ¥ä¸‹æ¥çš„å°èŠ‚ä¹Ÿä¼šå¯¹configæ–‡ä»¶çš„å†…å®¹åšè¯¦ç»†è®²è§£ã€‚

é…ç½®å¥½configæ–‡ä»¶åï¼Œåªéœ€è¦å°†configæ–‡ä»¶ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç å³å¯è¿›è¡Œè¯„æµ‹ï¼š

```bash
python pdf_validation.py --config <config_path>
```

### ç«¯åˆ°ç«¯è¯„æµ‹

ç«¯åˆ°ç«¯è¯„æµ‹æ˜¯å¯¹æ¨¡å‹åœ¨PDFé¡µé¢å†…å®¹è§£æä¸Šçš„ç²¾åº¦ä½œå‡ºçš„è¯„æµ‹ã€‚ä»¥æ¨¡å‹è¾“å‡ºçš„å¯¹æ•´ä¸ªPDFé¡µé¢è§£æç»“æœçš„Markdownä½œä¸ºPredictionã€‚

<table style="width: 92%; border-collapse: collapse; margin: 0 auto;">
  <caption>Comprehensive evaluation of document parsing algorithms on OmniDocBench: performance metrics for text, formula, table, and reading order extraction, with overall scores derived from ground truth comparisons.</caption>
  <thead>
    <tr>
      <th rowspan="2">Method Type</th>
      <th rowspan="2">Methods</th>
      <th colspan="2">Text<sup>Edit</sup>â†“</th>
      <th colspan="2">Formula<sup>Edit</sup>â†“</th>
      <th colspan="2">Formula<sup>CDM</sup>â†‘</th>
      <th colspan="2">Table<sup>TEDS</sup>â†‘</th>
      <th colspan="2">Table<sup>Edit</sup>â†“</th>
      <th colspan="2">Read Order<sup>Edit</sup>â†“</th>
      <th colspan="2">Overall<sup>Edit</sup>â†“</th>
    </tr>
    <tr>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
      <th>EN</th>
      <th>ZH</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="3">Pipeline Tools</td>
      <td>MinerU-0.9.3</td>
      <td><strong>0.058</strong></td>
      <td><strong>0.211</strong></td>
      <td><strong>0.278</strong></td>
      <td>0.577</td>
      <td>66.9</td>
      <td>49.5</td>
      <td><strong>79.4</strong></td>
      <td>62.7</td>
      <td><strong>0.305</strong></td>
      <td><u>0.461</u></td>
      <td><strong>0.079</strong></td>
      <td>0.288</td>
      <td><strong>0.180</strong></td>
      <td><u>0.384</u></td>
    </tr>
    <tr>
      <td>Marker-0.2.17</td>
      <td>0.141</td>
      <td>0.303</td>
      <td>0.667</td>
      <td>0.868</td>
      <td>18.4</td>
      <td>12.7</td>
      <td>54.0</td>
      <td>45.8</td>
      <td>0.718</td>
      <td>0.763</td>
      <td>0.138</td>
      <td>0.306</td>
      <td>0.416</td>
      <td>0.560</td>
    </tr>
    <tr>
      <td>Mathpix</td>
      <td><u>0.101</u></td>
      <td>0.358</td>
      <td><u>0.306</u></td>
      <td><strong>0.454</strong></td>
      <td>71.4</td>
      <td><strong>72.7</strong></td>
      <td><u>77.9</u></td>
      <td><strong>68.2</strong></td>
      <td><u>0.322</u></td>
      <td><strong>0.416</strong></td>
      <td><u>0.105</u></td>
      <td>0.275</td>
      <td><u>0.209</u></td>
      <td><strong>0.376</strong></td>
    </tr>
    <tr>
      <td rowspan="2">Expert VLMs</td>
      <td>GOT-OCR</td>
      <td>0.187</td>
      <td>0.315</td>
      <td>0.360</td>
      <td><u>0.528</u></td>
      <td><strong>81.8</strong></td>
      <td>51.4</td>
      <td>53.5</td>
      <td>48.0</td>
      <td>0.521</td>
      <td>0.594</td>
      <td>0.141</td>
      <td>0.28</td>
      <td>0.302</td>
      <td>0.429</td>
    </tr>
    <tr>
      <td>Nougat</td>
      <td>0.365</td>
      <td>0.998</td>
      <td>0.488</td>
      <td>0.941</td>
      <td>17.4</td>
      <td>16.9</td>
      <td>40.3</td>
      <td>0.0</td>
      <td>0.622</td>
      <td>1.000</td>
      <td>0.382</td>
      <td>0.954</td>
      <td>0.464</td>
      <td>0.973</td>
    </tr>
    <tr>
      <td rowspan="3">General VLMs</td>
      <td>GPT4o</td>
      <td>0.144</td>
      <td>0.409</td>
      <td>0.425</td>
      <td>0.606</td>
      <td><u>76.4</u></td>
      <td>48.2</td>
      <td>72.75</td>
      <td>63.7</td>
      <td>0.363</td>
      <td>0.474</td>
      <td>0.128</td>
      <td>0.251</td>
      <td>0.265</td>
      <td>0.435</td>
    </tr>
    <tr>
      <td>Qwen2-VL-72B</td>
      <td>0.252</td>
      <td><u>0.251</u></td>
      <td>0.468</td>
      <td>0.572</td>
      <td>54.9</td>
      <td><u>60.9</u></td>
      <td>59.9</td>
      <td><u>66.8</u></td>
      <td>0.591</td>
      <td>0.587</td>
      <td>0.255</td>
      <td><strong>0.223</strong></td>
      <td>0.392</td>
      <td>0.408</td>
    </tr>
    <tr>
      <td>InternVL2-Llama3-76B</td>
      <td>0.353</td>
      <td>0.290</td>
      <td>0.543</td>
      <td>0.701</td>
      <td>69.8</td>
      <td>49.6</td>
      <td>63.8</td>
      <td>61.1</td>
      <td>0.616</td>
      <td>0.638</td>
      <td>0.317</td>
      <td><u>0.228</u></td>
      <td>0.457</td>
      <td>0.464</td>
    </tr>
  </tbody>
</table>

æ›´å¤šåˆ†å±æ€§è¯„æµ‹ç»“æœåœ¨è®ºæ–‡ä¸­å±•ç¤ºã€‚

#### ç«¯åˆ°ç«¯è¯„æµ‹æ–¹æ³•-end2end

ç«¯åˆ°ç«¯è¯„æµ‹åˆ†ä¸ºä¸¤ç§æ–¹å¼ï¼š
- `end2end`: è¯¥æ–¹æ³•æ˜¯ç”¨OmniDocBenchçš„JSONæ–‡ä»¶ä½œä¸ºGround Truth, configæ–‡ä»¶è¯·å‚è€ƒï¼š[end2end](./configs/end2end.yaml)
- `md2md`: è¯¥æ–¹æ³•æ˜¯ç”¨OmniDocBenchçš„markdownæ ¼å¼ä½œä¸ºGround Truthã€‚å…·ä½“å†…å®¹å°†åœ¨ä¸‹ä¸€å°èŠ‚*markdown-to-markdownè¯„æµ‹*ä¸­è¯¦è¿°ã€‚

æˆ‘ä»¬æ¨èä½¿ç”¨`end2end`çš„è¯„æµ‹æ–¹å¼ï¼Œå› ä¸ºè¯¥æ–¹å¼å¯ä»¥ä¿ç•™sampleçš„ç±»åˆ«å’Œå±æ€§ä¿¡æ¯ï¼Œä»è€Œå¸®åŠ©è¿›è¡Œç‰¹æ®Šç±»åˆ«ignoreçš„æ“ä½œï¼Œä»¥åŠåˆ†å±æ€§çš„ç»“æœè¾“å‡ºã€‚

`end2end`çš„è¯„æµ‹å¯ä»¥å¯¹å››ä¸ªç»´åº¦è¿›è¡Œè¯„æµ‹ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªend2endçš„è¯„æµ‹ç»“æœç¤ºä¾‹åœ¨[result](./result)ä¸­ï¼ŒåŒ…æ‹¬:
- æ–‡æœ¬æ®µè½
- è¡Œé—´å…¬å¼
- è¡¨æ ¼
- é˜…è¯»é¡ºåº

<details>
  <summary>end2end.yamlçš„å­—æ®µè§£é‡Š</summary>

`end2end.yaml`çš„é…ç½®å¦‚ä¸‹ï¼š

```YAML
end2end_eval:          # æŒ‡å®štaskåç§°ï¼Œç«¯åˆ°ç«¯è¯„æµ‹é€šç”¨è¯¥task
  metrics:             # é…ç½®éœ€è¦ä½¿ç”¨çš„metric
    text_block:        # é’ˆå¯¹æ–‡æœ¬æ®µè½çš„é…ç½®
      metric:
        - Edit_dist    # Normalized Edit Distance
        - BLEU         
        - METEOR
    display_formula:   # é’ˆå¯¹è¡Œé—´å…¬å¼çš„é…ç½®
      metric:
        - Edit_dist
        - CDM          # ä»…æ”¯æŒå¯¼å‡ºCDMè¯„æµ‹æ‰€éœ€çš„æ ¼å¼ï¼Œå­˜å‚¨åœ¨resultsä¸­
    table:             # é’ˆå¯¹è¡¨æ ¼çš„é…ç½®
      metric:
        - TEDS
        - Edit_dist
    reading_order:     # é’ˆå¯¹é˜…è¯»é¡ºåºçš„é…ç½®
      metric:
        - Edit_dist
  dataset:                                       # æ•°æ®é›†é…ç½®
    dataset_name: end2end_dataset                # æ•°æ®é›†åç§°ï¼Œæ— éœ€ä¿®æ”¹
    ground_truth:
      data_path: ./demo_data/omnidocbench_demo/OmniDocBench_demo.json  # OmniDocBenchçš„è·¯å¾„
    prediction:
      data_path: ./demo_data/end2end            # æ¨¡å‹å¯¹PDFé¡µé¢è§£æmarkdownç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„
    match_method: quick_match                    # åŒ¹é…æ–¹å¼ï¼Œå¯é€‰æœ‰: no_split/no_split/quick_match
    filter:                                      # é¡µé¢çº§åˆ«çš„ç­›é€‰
      language: english                          # éœ€è¦è¯„æµ‹çš„é¡µé¢å±æ€§ä»¥åŠå¯¹åº”æ ‡ç­¾
```

`prediction`ä¸‹çš„`data_path`è¾“å…¥çš„æ˜¯æ¨¡å‹å¯¹PDFé¡µé¢è§£æç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œè·¯å¾„ä¸­ä¿å­˜çš„æ˜¯æ¯ä¸ªé¡µé¢å¯¹åº”çš„markdownï¼Œæ–‡ä»¶åä¸å›¾ç‰‡åä¿æŒä¸€è‡´ï¼Œä»…å°†.jpgåç¼€æ›¿æ¢æˆ.mdã€‚

é™¤äº†å·²æ”¯æŒçš„metricä»¥å¤–ï¼Œè¿˜æ”¯æŒå¯¼å‡º[CDM](https://github.com/opendatalab/UniMERNet/tree/main/cdm)è¯„æµ‹æ‰€éœ€çš„æ ¼å¼ï¼Œåªéœ€è¦åœ¨metricä¸­é…ç½®CDMå­—æ®µï¼Œå³å¯å°†è¾“å‡ºæ•´ç†ä¸ºCDMçš„è¾“å…¥æ ¼å¼ï¼Œå¹¶å­˜å‚¨åœ¨[result](./result)ä¸­ã€‚

åœ¨ç«¯åˆ°ç«¯çš„è¯„æµ‹ä¸­ï¼Œconfigé‡Œå¯ä»¥é€‰æ‹©é…ç½®ä¸åŒçš„åŒ¹é…æ–¹å¼ï¼Œä¸€å…±æœ‰ä¸‰ç§åŒ¹é…æ–¹å¼ï¼š
- `no_split`: ä¸å¯¹text blockåšæ‹†åˆ†å’ŒåŒ¹é…çš„æ“ä½œï¼Œè€Œæ˜¯ç›´æ¥åˆå¹¶æˆä¸€æ•´ä¸ªmarkdownè¿›è¡Œè®¡ç®—ï¼Œè¿™ç§æ–¹å¼ä¸‹ï¼Œå°†ä¸ä¼šè¾“å‡ºåˆ†å±æ€§çš„ç»“æœï¼Œä¹Ÿä¸ä¼šè¾“å‡ºé˜…è¯»é¡ºåºçš„ç»“æœï¼›
- `simple_match`: ä¸è¿›è¡Œä»»ä½•æˆªæ–­åˆå¹¶æ“ä½œï¼Œä»…å¯¹æ–‡æœ¬åšåŒæ¢è¡Œçš„æ®µè½åˆ†å‰²åï¼Œç›´æ¥ä¸GTè¿›è¡Œä¸€å¯¹ä¸€åŒ¹é…ï¼›
- `quick_match`ï¼šåœ¨æ®µè½åˆ†å‰²çš„åŸºç¡€ä¸Šï¼ŒåŠ ä¸Šæˆªæ–­åˆå¹¶çš„æ“ä½œï¼Œå‡å°‘æ®µè½åˆ†å‰²å·®å¼‚å¯¹æœ€ç»ˆç»“æœçš„å½±å“ï¼Œé€šè¿‡*Adjacency Search Match*çš„æ–¹å¼è¿›è¡Œæˆªæ–­åˆå¹¶ï¼›

æˆ‘ä»¬æ¨èä½¿ç”¨`quick_match`çš„æ–¹å¼ä»¥è¾¾åˆ°è¾ƒå¥½çš„åŒ¹é…æ•ˆæœï¼Œä½†å¦‚æœæ¨¡å‹è¾“å‡ºçš„æ®µè½åˆ†å‰²è¾ƒå‡†ç¡®ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨`simple_match`çš„æ–¹å¼ï¼Œè¯„æµ‹è¿è¡Œä¼šæ›´åŠ è¿…é€Ÿã€‚åŒ¹é…æ–¹æ³•é€šè¿‡`config`ä¸­çš„`dataset`å­—æ®µä¸‹çš„`match_method`å­—æ®µè¿›è¡Œé…ç½®ã€‚

ä½¿ç”¨`filter`å­—æ®µå¯ä»¥å¯¹æ•°æ®é›†è¿›è¡Œç­›é€‰ï¼Œæ¯”å¦‚å°†`dataset`ä¸‹è®¾ç½®`filter`å­—æ®µä¸º`language: english`ï¼Œå°†ä¼šä»…è¯„æµ‹é¡µé¢è¯­è¨€ä¸ºè‹±æ–‡çš„é¡µé¢ã€‚æ›´å¤šé¡µé¢å±æ€§è¯·å‚è€ƒ*è¯„æµ‹é›†ä»‹ç»*éƒ¨åˆ†ã€‚å¦‚æœå¸Œæœ›å…¨é‡è¯„æµ‹ï¼Œè¯·æ³¨é‡Šæ‰`filter`ç›¸å…³å­—æ®µã€‚

</details>


#### ç«¯åˆ°ç«¯è¯„æµ‹æ–¹æ³•-md2md

markdown-to-markdownè¯„æµ‹ä»¥æ¨¡å‹è¾“å‡ºçš„å¯¹æ•´ä¸ªPDFé¡µé¢è§£æç»“æœçš„Markdownä½œä¸ºPredictionï¼Œç”¨OmniDocBenchçš„markdownæ ¼å¼ä½œä¸ºGround Truthã€‚configæ–‡ä»¶è¯·å‚è€ƒï¼š[md2md](./configs/md2md.yaml)ã€‚æˆ‘ä»¬æ›´åŠ æ¨èä½¿ç”¨ä¸Šä¸€èŠ‚çš„`end2end`çš„æ–¹å¼ä½¿ç”¨OmniDocBenchè¿›è¡Œè¯„æµ‹ï¼Œä»è€Œä¿ç•™ä¸°å¯Œçš„å±æ€§æ ‡æ³¨ä»¥åŠignoreé€»è¾‘ã€‚ä½†æ˜¯æˆ‘ä»¬ä¾ç„¶æä¾›äº†`md2md`çš„è¯„æµ‹æ–¹æ³•ï¼Œä»¥ä¾¿äºä¸ç°æœ‰çš„è¯„æµ‹æ–¹å¼å¯¹é½ã€‚

`md2md`çš„è¯„æµ‹å¯ä»¥å¯¹ä¸‰ä¸ªç»´åº¦è¿›è¡Œè¯„æµ‹ï¼ŒåŒ…æ‹¬:
- æ–‡æœ¬æ®µè½
- è¡Œé—´å…¬å¼
- è¡¨æ ¼
- é˜…è¯»é¡ºåº

<details>
  <summary>md2md.yamlçš„å­—æ®µè§£é‡Š</summary>

`md2md.yaml`çš„é…ç½®å¦‚ä¸‹ï¼š

```YAML
end2end_eval:          # æŒ‡å®štaskåç§°ï¼Œç«¯åˆ°ç«¯è¯„æµ‹é€šç”¨è¯¥task
  metrics:             # é…ç½®éœ€è¦ä½¿ç”¨çš„metric
    text_block:        # é’ˆå¯¹æ–‡æœ¬æ®µè½çš„é…ç½®
      metric:
        - Edit_dist    # Normalized Edit Distance
        - BLEU         
        - METEOR
    display_formula:   # é’ˆå¯¹è¡Œé—´å…¬å¼çš„é…ç½®
      metric:
        - Edit_dist
        - CDM          # ä»…æ”¯æŒå¯¼å‡ºCDMè¯„æµ‹æ‰€éœ€çš„æ ¼å¼ï¼Œå­˜å‚¨åœ¨resultsä¸­
    table:             # é’ˆå¯¹è¡¨æ ¼çš„é…ç½®
      metric:
        - TEDS
        - Edit_dist
    reading_order:     # é’ˆå¯¹é˜…è¯»é¡ºåºçš„é…ç½®
      metric:
        - Edit_dist
  dataset:                                               # æ•°æ®é›†é…ç½®
    dataset_name: md2md_dataset                          # æ•°æ®é›†åç§°ï¼Œæ— éœ€ä¿®æ”¹
    ground_truth:                                        # é’ˆå¯¹ground truthçš„æ•°æ®é›†é…ç½®
      data_path: ./demo_data/omnidocbench_demo/mds       # OmniDocBenchçš„markdownæ–‡ä»¶å¤¹è·¯å¾„
      page_info: ./demo_data/omnidocbench_demo/OmniDocBench_demo.json          # OmniDocBenchçš„JSONæ–‡ä»¶è·¯å¾„ï¼Œä¸»è¦æ˜¯ç”¨äºè·å–é¡µé¢çº§åˆ«çš„å±æ€§
    prediction:                                          # é’ˆå¯¹æ¨¡å‹é¢„æµ‹ç»“æœçš„é…ç½®
      data_path: ./demo_data/end2end                     # æ¨¡å‹å¯¹PDFé¡µé¢è§£æmarkdownç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„
    match_method: quick_match                            # åŒ¹é…æ–¹å¼ï¼Œå¯é€‰æœ‰: no_split/no_split/quick_match
    filter:                                              # é¡µé¢çº§åˆ«çš„ç­›é€‰
      language: english                                  # éœ€è¦è¯„æµ‹çš„é¡µé¢å±æ€§ä»¥åŠå¯¹åº”æ ‡ç­¾
```

`prediction`ä¸‹çš„`data_path`è¾“å…¥çš„æ˜¯æ¨¡å‹å¯¹PDFé¡µé¢è§£æç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œè·¯å¾„ä¸­ä¿å­˜çš„æ˜¯æ¯ä¸ªé¡µé¢å¯¹åº”çš„markdownï¼Œæ–‡ä»¶åä¸å›¾ç‰‡åä¿æŒä¸€è‡´ï¼Œä»…å°†`.jpg`åç¼€æ›¿æ¢æˆ`.md`ã€‚

`ground_truth`ä¸‹çš„`data_path`è¾“å…¥çš„æ˜¯OmniDocBenchçš„markdownæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¸æ¨¡å‹å¯¹PDFé¡µé¢è§£æç»“æœçš„markdownæ–‡ä»¶åä¸€ä¸€å¯¹åº”ã€‚`ground_truth`ä¸‹çš„`page_info`è·¯å¾„è¾“å…¥çš„æ˜¯OmniDocBenchçš„JSONæ–‡ä»¶è·¯å¾„ï¼Œä¸»è¦æ˜¯ç”¨äºè·å–é¡µé¢çº§åˆ«çš„å±æ€§ã€‚å¦‚æœä¸éœ€è¦é¡µé¢çº§åˆ«åˆ†å±æ€§çš„è¯„æµ‹ç»“æœè¾“å‡ºï¼Œä¹Ÿå¯ä»¥ç›´æ¥å°†è¯¥å­—æ®µæ³¨é‡Šæ‰ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ²¡æœ‰é…ç½®`ground_truth`ä¸‹çš„`page_info`å­—æ®µï¼Œå°±æ— æ³•ä½¿ç”¨`filter`ç›¸å…³åŠŸèƒ½ã€‚

é™¤æ­¤ä¹‹å¤–çš„configä¸­å­—æ®µçš„è§£é‡Šè¯·å‚è€ƒ*ç«¯åˆ°ç«¯è¯„æµ‹-end2end*å°èŠ‚ã€‚

</details>

### å…¬å¼è¯†åˆ«è¯„æµ‹

OmniDocBenchåŒ…å«æ¯ä¸ªPDFé¡µé¢çš„å…¬å¼çš„bounding boxä¿¡æ¯ä»¥åŠå¯¹åº”çš„å…¬å¼è¯†åˆ«æ ‡æ³¨ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºå…¬å¼è¯†åˆ«è¯„æµ‹çš„benchmarkã€‚å…¬å¼åŒ…æ‹¬è¡Œé—´å…¬å¼`equation_isolated`å’Œè¡Œå†…å…¬å¼`equation_inline`ï¼Œæœ¬repoç›®å‰æä¾›çš„ä¾‹å­æ˜¯è¡Œé—´å…¬å¼çš„è¯„æµ‹ã€‚

<table style="width: 47%;">
  <thead>
    <tr>
      <th>Models</th>
      <th>CDM</th>
      <th>ExpRate@CDM</th>
      <th>BLEU</th>
      <th>Norm Edit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GOT-OCR</td>
      <td>74.1</td>
      <td>28.0</td>
      <td>55.07</td>
      <td>0.290</td>
    </tr>
    <tr>
      <td>Mathpix</td>
      <td><u>86.6</u></td>
      <td>2.8</td>
      <td><b>66.56</b></td>
      <td>0.322</td>
    </tr>
    <tr>
      <td>Pix2Tex</td>
      <td>73.9</td>
      <td>39.5</td>
      <td>46.00</td>
      <td>0.337</td>
    </tr>
    <tr>
      <td>UniMERNet-B</td>
      <td>85.0</td>
      <td><u>60.2</u></td>
      <td><u>60.84</u></td>
      <td><b>0.238</b></td>
    </tr>
    <tr>
      <td>GPT4o</td>
      <td><b>86.8</b></td>
      <td><b>65.5</b></td>
      <td>45.17</td>
      <td><u>0.282</u></td>
    </tr>
    <tr>
      <td>InternVL2-Llama3-76B</td>
      <td>67.4</td>
      <td>54.5</td>
      <td>47.63</td>
      <td>0.308</td>
    </tr>
    <tr>
      <td>Qwen2-VL-72B</td>
      <td>83.8</td>
      <td>55.4</td>
      <td>53.71</td>
      <td>0.285</td>
    </tr>
  </tbody>
</table>
<p>Component-level formula recognition evaluation on OmniDocBench formula subset.</p>


å…¬å¼è¯†åˆ«è¯„æµ‹å¯ä»¥å‚è€ƒ[formula_recognition](./configs/formula_recognition.yaml)è¿›è¡Œé…ç½®ã€‚ 

<details>
  <summary>formula_recognition.yamlçš„å­—æ®µè§£é‡Š</summary>

`formula_recognition.yaml`çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```YAML
recogition_eval:      # æŒ‡å®štaskåç§°ï¼Œæ‰€æœ‰çš„è¯†åˆ«ç›¸å…³çš„ä»»åŠ¡é€šç”¨æ­¤task
  metrics:            # é…ç½®éœ€è¦ä½¿ç”¨çš„metric
    - Edit_dist       # Normalized Edit Distance
    - CDM             # ä»…æ”¯æŒå¯¼å‡ºCDMè¯„æµ‹æ‰€éœ€çš„æ ¼å¼ï¼Œå­˜å‚¨åœ¨resultsä¸­
  dataset:                                                                   # æ•°æ®é›†é…ç½®
    dataset_name: omnidocbench_single_module_dataset                         # æ•°æ®é›†åç§°ï¼Œå¦‚æœæŒ‰ç…§è§„å®šçš„è¾“å…¥æ ¼å¼åˆ™ä¸éœ€è¦ä¿®æ”¹
    ground_truth:                                                            # é’ˆå¯¹ground truthçš„æ•°æ®é›†é…ç½®
      data_path: ./demo_data/recognition/OmniDocBench_demo_formula.json      # åŒæ—¶åŒ…å«ground truthå’Œæ¨¡å‹predictionç»“æœçš„JSONæ–‡ä»¶
      data_key: latex                                                        # å­˜å‚¨Ground Truthçš„å­—æ®µåï¼Œå¯¹äºOmniDocBenchæ¥è¯´ï¼Œå…¬å¼çš„è¯†åˆ«ç»“æœå­˜å‚¨åœ¨latexè¿™ä¸ªå­—æ®µä¸­
      category_filter: ['equation_isolated']                                 # ç”¨äºè¯„æµ‹çš„ç±»åˆ«ï¼Œåœ¨å…¬å¼è¯†åˆ«ä¸­ï¼Œè¯„æµ‹çš„category_nameæ˜¯equation_isolated
    prediction:                                                              # é’ˆå¯¹æ¨¡å‹é¢„æµ‹ç»“æœçš„é…ç½®
      data_key: pred                                                         # å­˜å‚¨æ¨¡å‹é¢„æµ‹ç»“æœçš„å­—æ®µåï¼Œè¿™ä¸ªæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„
    category_type: formula                                                   # category_typeä¸»è¦æ˜¯ç”¨äºæ•°æ®é¢„å¤„ç†ç­–ç•¥çš„é€‰æ‹©ï¼Œå¯é€‰é¡¹æœ‰ï¼šformula/text
```

`metrics`éƒ¨åˆ†ï¼Œé™¤äº†å·²æ”¯æŒçš„metricä»¥å¤–ï¼Œè¿˜æ”¯æŒå¯¼å‡º[CDM](https://github.com/opendatalab/UniMERNet/tree/main/cdm)è¯„æµ‹æ‰€éœ€çš„æ ¼å¼ï¼Œåªéœ€è¦åœ¨metricä¸­é…ç½®CDMå­—æ®µï¼Œå³å¯å°†è¾“å‡ºæ•´ç†ä¸ºCDMçš„è¾“å…¥æ ¼å¼ï¼Œå¹¶å­˜å‚¨åœ¨[result](./result)ä¸­ã€‚

`dataset`çš„éƒ¨åˆ†ï¼Œè¾“å…¥çš„`ground_truth`çš„`data_path`ä¸­çš„æ•°æ®æ ¼å¼ä¸OmniDocBenchä¿æŒä¸€è‡´ï¼Œä»…å¯¹åº”çš„å…¬å¼sampleä¸‹æ–°å¢ä¸€ä¸ªè‡ªå®šä¹‰å­—æ®µä¿å­˜æ¨¡å‹çš„predictionç»“æœã€‚é€šè¿‡`dataset`ä¸‹çš„`prediction`å­—æ®µä¸‹çš„`data_key`å¯¹å­˜å‚¨äº†predictionä¿¡æ¯çš„å­—æ®µè¿›è¡ŒæŒ‡å®šï¼Œæ¯”å¦‚`pred`ã€‚å…³äºæ›´å¤šOmniDocBenchçš„æ–‡ä»¶ç»“æ„ç»†èŠ‚è¯·å‚è€ƒ`è¯„æµ‹é›†ä»‹ç»`å°èŠ‚ã€‚æ¨¡å‹ç»“æœçš„è¾“å…¥æ ¼å¼å¯ä»¥å‚è€ƒ[OmniDocBench_demo_formula](./demo_data/recognition/OmniDocBench_demo_formula.json)ï¼Œå…¶æ ¼å¼ä¸ºï¼š

```JSON
[{
    "layout_dets": [    // é¡µé¢å…ƒç´ åˆ—è¡¨
        {
            "category_type": "equation_isolated",  // OmniDocBenchç±»åˆ«åç§°
            "poly": [    // OmniDocBenchä½ç½®ä¿¡æ¯ï¼Œåˆ†åˆ«æ˜¯å·¦ä¸Šè§’ã€å³ä¸Šè§’ã€å³ä¸‹è§’ã€å·¦ä¸‹è§’çš„x,yåæ ‡
                136.0, 
                781.0,
                340.0,
                781.0,
                340.0,
                806.0,
                136.0,
                806.0
            ],
            ...   // å…¶ä»–OmniDocBenchå­—æ®µ
            "latex": "$xxx$",  // formulaçš„LaTeXä¼šå†™åœ¨è¿™é‡Œ
            "pred": "$xxx$",   // !! æ¨¡å‹çš„predictionç»“æœå­˜å‚¨åœ¨è¿™é‡Œï¼Œç”±ç”¨æˆ·è‡ªå®šä¹‰ä¸€ä¸ªæ–°å¢å­—æ®µï¼Œå­˜å‚¨åœ¨ä¸ground truthåŒçº§
            
        ...
    ],
    "page_info": {...},        // OmniDocBenché¡µé¢ä¿¡æ¯
    "extra": {...}             // OmniDocBenchæ ‡æ³¨é—´å…³ç³»ä¿¡æ¯
},
...
]
```

åœ¨æ­¤æä¾›ä¸€ä¸ªæ¨¡å‹inferçš„è„šæœ¬ä¾›å‚è€ƒï¼š

```PYTHON
import os
import json
from PIL import Image

def poly2bbox(poly):
    L = poly[0]
    U = poly[1]
    R = poly[2]
    D = poly[5]
    L, R = min(L, R), max(L, R)
    U, D = min(U, D), max(U, D)
    bbox = [L, U, R, D]
    return bbox

question = "<image>\nPlease convert this cropped image directly into latex."

with open('./demo_data/omnidocbench_demo/OmniDocBench_demo.json', 'r') as f:
    samples = json.load(f)
    
for sample in samples:
    img_name = os.path.basename(sample['page_info']['image_path'])
    img_path = os.path.join('./Docparse/images', img_name)
    img = Image.open(img_path)

    if not os.path.exists(img_path):
        print('No exist: ', img_name)
        continue

    for i, anno in enumerate(sample['layout_dets']):
        if anno['category_type'] != 'equation_isolated':   # ç­›é€‰å‡ºè¡Œé—´å…¬å¼ç±»åˆ«è¿›è¡Œè¯„æµ‹
            continue

        bbox = poly2bbox(anno['poly'])
        im = img.crop(bbox).convert('RGB')
        response = model.chat(im, question)  # éœ€è¦æ ¹æ®æ¨¡å‹ä¿®æ”¹ä¼ å…¥å›¾ç‰‡çš„æ–¹å¼
        anno['pred'] = response              # ç›´æ¥åœ¨å¯¹åº”çš„annotationä¸‹æ–°å¢å­—æ®µå­˜å‚¨æ¨¡å‹çš„inferç»“æœ

with open('./demo_data/recognition/OmniDocBench_demo_formula.json', 'w', encoding='utf-8') as f:
    json.dump(samples, f, ensure_ascii=False)
```

</details>

### æ–‡å­—OCRè¯„æµ‹

OmniDocBenchåŒ…å«æ¯ä¸ªPDFé¡µé¢çš„æ‰€æœ‰æ–‡å­—çš„bounding boxä¿¡æ¯ä»¥åŠå¯¹åº”çš„æ–‡å­—è¯†åˆ«æ ‡æ³¨ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºOCRè¯„æµ‹çš„benchmarkã€‚æ–‡æœ¬çš„æ ‡æ³¨åŒ…å«block_levelçš„æ ‡æ³¨å’Œspan_levelçš„æ ‡æ³¨ï¼Œéƒ½å¯ä»¥ç”¨äºè¯„æµ‹ã€‚æœ¬repoç›®å‰æä¾›çš„ä¾‹å­æ˜¯block_levelçš„è¯„æµ‹ï¼Œå³æ–‡æœ¬æ®µè½çº§åˆ«çš„OCRè¯„æµ‹ã€‚

<table style="width: 90%; font-size: small; margin: 0 auto; border-collapse: collapse;">
    <caption style="caption-side: bottom; padding-top: 4px;">Component-level evaluation on OmniDocBench OCR subset: results grouped by text attributes using the edit distance metric.</caption>
    <thead>
        <tr>
            <th rowspan="2" style="border-bottom: 1px solid #000;">Model Type</th>
            <th rowspan="2" style="border-bottom: 1px solid #000;">Model</th>
            <th colspan="3" style="border-bottom: 1px solid #000;">Language</th>
            <th colspan="3" style="border-bottom: 1px solid #000;">Text background</th>
            <th colspan="4" style="border-bottom: 1px solid #000;">Text Rotate</th>
        </tr>
        <tr>
            <th style="border-bottom: 1px solid #000;">EN</th>
            <th style="border-bottom: 1px solid #000;">ZH</th>
            <th style="border-bottom: 1px solid #000;">Mixed</th>
            <th style="border-bottom: 1px solid #000;">White</th>
            <th style="border-bottom: 1px solid #000;">Single</th>
            <th style="border-bottom: 1px solid #000;">Multi</th>
            <th style="border-bottom: 1px solid #000;">Normal</th>
            <th style="border-bottom: 1px solid #000;">Rotate90</th>
            <th style="border-bottom: 1px solid #000;">Rotate270</th>
            <th style="border-bottom: 1px solid #000;">Horizontal</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan="5">Expert Vision Models</td>
            <td>PaddleOCR</td>
            <td>0.071</td>
            <td><strong>0.055</strong></td>
            <td><strong>0.118</strong></td>
            <td><strong>0.060</strong></td>
            <td><strong>0.038</strong></td>
            <td><strong>0.0848</strong></td>
            <td><strong>0.060</strong></td>
            <td><strong>0.015</strong></td>
            <td style="text-decoration: underline;">0.285</td>
            <td><strong>0.021</strong></td>
        </tr>
        <tr>
            <td>Tesseract OCR</td>
            <td>0.179</td>
            <td>0.553</td>
            <td>0.553</td>
            <td>0.453</td>
            <td>0.463</td>
            <td>0.394</td>
            <td>0.448</td>
            <td>0.369</td>
            <td>0.979</td>
            <td>0.982</td>
        </tr>
        <tr>
            <td>Surya</td>
            <td>0.057</td>
            <td>0.123</td>
            <td>0.164</td>
            <td>0.093</td>
            <td>0.186</td>
            <td>0.235</td>
            <td>0.104</td>
            <td>0.634</td>
            <td>0.767</td>
            <td>0.255</td>
        </tr>
        <tr>
            <td>GOT-OCR</td>
            <td>0.041</td>
            <td style="text-decoration: underline;">0.112</td>
            <td>0.135</td>
            <td style="text-decoration: underline;">0.092</td>
            <td style="text-decoration: underline;">0.052</td>
            <td>0.155</td>
            <td style="text-decoration: underline;">0.091</td>
            <td>0.562</td>
            <td>0.966</td>
            <td>0.097</td>
        </tr>
        <tr>
            <td>Mathpix</td>
            <td style="text-decoration: underline;">0.033</td>
            <td>0.240</td>
            <td>0.261</td>
            <td>0.185</td>
            <td>0.121</td>
            <td>0.166</td>
            <td>0.180</td>
            <td style="text-decoration: underline;">0.038</td>
            <td><strong>0.185</strong></td>
            <td>0.638</td>
        </tr>
        <tr>
            <td rowspan="3">Vision Language Models</td>
            <td>Qwen2-VL-72B</td>
            <td>0.072</td>
            <td>0.274</td>
            <td>0.286</td>
            <td>0.234</td>
            <td>0.155</td>
            <td style="text-decoration: underline;">0.148</td>
            <td>0.223</td>
            <td>0.273</td>
            <td>0.721</td>
            <td style="text-decoration: underline;">0.067</td>
        </tr>
        <tr>
            <td>InternVL2-Llama3-76B</td>
            <td>0.074</td>
            <td>0.155</td>
            <td>0.242</td>
            <td>0.113</td>
            <td>0.352</td>
            <td>0.269</td>
            <td>0.132</td>
            <td>0.610</td>
            <td>0.907</td>
            <td>0.595</td>
        </tr>
        <tr>
            <td>GPT4o</td>
            <td><strong>0.020</strong></td>
            <td>0.224</td>
            <td style="text-decoration: underline;">0.125</td>
            <td>0.167</td>
            <td>0.140</td>
            <td>0.220</td>
            <td>0.168</td>
            <td>0.115</td>
            <td>0.718</td>
            <td>0.132</td>
        </tr>
    </tbody>
</table>


æ–‡å­—OCRè¯„æµ‹å¯ä»¥å‚è€ƒ[ocr](./configs/ocr.yaml)è¿›è¡Œé…ç½®ã€‚ 

<details>
  <summary>ocr.yamlçš„å­—æ®µè§£é‡Š</summary>

`ocr.yaml`çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```YAML
recogition_eval:      # æŒ‡å®štaskåç§°ï¼Œæ‰€æœ‰çš„è¯†åˆ«ç›¸å…³çš„ä»»åŠ¡é€šç”¨æ­¤task
  metrics:            # é…ç½®éœ€è¦ä½¿ç”¨çš„metric
    - Edit_dist       # Normalized Edit Distance
    - BLEU
    - METEOR
  dataset:                                                                   # æ•°æ®é›†é…ç½®
    dataset_name: omnidocbench_single_module_dataset                         # æ•°æ®é›†åç§°ï¼Œå¦‚æœæŒ‰ç…§è§„å®šçš„è¾“å…¥æ ¼å¼åˆ™ä¸éœ€è¦ä¿®æ”¹
    ground_truth:                                                            # é’ˆå¯¹ground truthçš„æ•°æ®é›†é…ç½®
      data_path: ./demo_data/recognition/OmniDocBench_demo_text_ocr.json     # åŒæ—¶åŒ…å«ground truthå’Œæ¨¡å‹predictionç»“æœçš„JSONæ–‡ä»¶
      data_key: text                                                         # å­˜å‚¨Ground Truthçš„å­—æ®µåï¼Œå¯¹äºOmniDocBenchæ¥è¯´ï¼Œæ–‡æœ¬è¯†åˆ«ç»“æœå­˜å‚¨åœ¨textè¿™ä¸ªå­—æ®µä¸­ï¼Œæ‰€æœ‰block levelåªè¦åŒ…å«textå­—æ®µçš„annotationséƒ½ä¼šå‚ä¸è¯„æµ‹
    prediction:                                                              # é’ˆå¯¹æ¨¡å‹é¢„æµ‹ç»“æœçš„é…ç½®
      data_key: pred                                                         # å­˜å‚¨æ¨¡å‹é¢„æµ‹ç»“æœçš„å­—æ®µåï¼Œè¿™ä¸ªæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„
    category_type: text                                                      # category_typeä¸»è¦æ˜¯ç”¨äºæ•°æ®é¢„å¤„ç†ç­–ç•¥çš„é€‰æ‹©ï¼Œå¯é€‰é¡¹æœ‰ï¼šformula/text
```

`dataset`çš„éƒ¨åˆ†ï¼Œè¾“å…¥çš„`ground_truth`çš„`data_path`ä¸­çš„æ•°æ®æ ¼å¼ä¸OmniDocBenchä¿æŒä¸€è‡´ï¼Œä»…å¯¹åº”çš„å«æœ‰textå­—æ®µçš„sampleä¸‹æ–°å¢ä¸€ä¸ªè‡ªå®šä¹‰å­—æ®µä¿å­˜æ¨¡å‹çš„predictionç»“æœã€‚é€šè¿‡`dataset`ä¸‹çš„`prediction`å­—æ®µä¸‹çš„`data_key`å¯¹å­˜å‚¨äº†predictionä¿¡æ¯çš„å­—æ®µè¿›è¡ŒæŒ‡å®šï¼Œæ¯”å¦‚`pred`ã€‚æ•°æ®é›†çš„è¾“å…¥æ ¼å¼å¯ä»¥å‚è€ƒ[OmniDocBench_demo_text_ocr](./demo_data/recognition/OmniDocBench_demo_text_ocr.json)ï¼Œå„ä¸ªå­—æ®µå«ä¹‰å¯ä»¥å‚è€ƒ*å…¬å¼è¯†åˆ«è¯„æµ‹*éƒ¨åˆ†æä¾›çš„æ ·ä¾‹ã€‚

åœ¨æ­¤æä¾›ä¸€ä¸ªæ¨¡å‹inferçš„è„šæœ¬ä¾›å‚è€ƒï¼š

```PYTHON
import os
import json
from PIL import Image

def poly2bbox(poly):
    L = poly[0]
    U = poly[1]
    R = poly[2]
    D = poly[5]
    L, R = min(L, R), max(L, R)
    U, D = min(U, D), max(U, D)
    bbox = [L, U, R, D]
    return bbox

question = "<image>\nPlease convert this cropped image directly into latex."

with open('./demo_data/omnidocbench_demo/OmniDocBench_demo.json', 'r') as f:
    samples = json.load(f)
    
for sample in samples:
    img_name = os.path.basename(sample['page_info']['image_path'])
    img_path = os.path.join('./Docparse/images', img_name)
    img = Image.open(img_path)

    if not os.path.exists(img_path):
        print('No exist: ', img_name)
        continue

    for i, anno in enumerate(sample['layout_dets']):
        if not anno.get('text'):             # ç­›é€‰å‡ºOmniDocBenchä¸­åŒ…å«textå­—æ®µçš„annotationsè¿›è¡Œæ¨¡å‹infer
            continue

        bbox = poly2bbox(anno['poly'])
        im = img.crop(bbox).convert('RGB')
        response = model.chat(im, question)  # éœ€è¦æ ¹æ®æ¨¡å‹ä¿®æ”¹ä¼ å…¥å›¾ç‰‡çš„æ–¹å¼
        anno['pred'] = response              # ç›´æ¥åœ¨å¯¹åº”çš„annotationä¸‹æ–°å¢å­—æ®µå­˜å‚¨æ¨¡å‹çš„inferç»“æœ

with open('./demo_data/recognition/OmniDocBench_demo_text_ocr.json', 'w', encoding='utf-8') as f:
    json.dump(samples, f, ensure_ascii=False)
```

</details>

### è¡¨æ ¼è¯†åˆ«è¯„æµ‹

OmniDocBenchåŒ…å«æ¯ä¸ªPDFé¡µé¢çš„å…¬å¼çš„bounding boxä¿¡æ¯ä»¥åŠå¯¹åº”çš„è¡¨æ ¼è¯†åˆ«æ ‡æ³¨ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºè¡¨æ ¼è¯†åˆ«è¯„æµ‹çš„benchmarkã€‚è¡¨æ ¼è¯†åˆ«çš„æ ‡æ³¨åŒ…å«HTMLå’ŒLaTexä¸¤ç§æ ¼å¼ï¼Œæœ¬repoç›®å‰æä¾›çš„ä¾‹å­æ˜¯HTMLæ ¼å¼çš„è¯„æµ‹ã€‚

<table style="width:100%; border-collapse: collapse;">
<thead>
    <tr>
      <th rowspan="2">Model Type</th>
      <th rowspan="2">Model</th>
      <th colspan="3">Language</th>
      <th colspan="4">Table Frame Type</th>
      <th colspan="4">Special Situation</th>
      <th rowspan="2">Overall</th>
    </tr>
    <tr>
      <th><i>EN</i></th>
      <th><i>ZH</i></th>
      <th><i>Mixed</i></th>
      <th><i>Full</i></th>
      <th><i>Omission</i></th>
      <th><i>Three</i></th>
      <th><i>Zero</i></th>
      <th><i>Merge Cell</i>(+/-)</th>
      <th><i>Formula</i>(+/-)</th>
      <th><i>Colorful</i>(+/-)</th>
      <th><i>Rotate</i>(+/-)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="2"><strong>OCR-based Models</strong></td>
      <td>PaddleOCR</td>
      <td><u>76.8</u></td>
      <td>71.8</td>
      <td>80.1</td>
      <td>67.9</td>
      <td><u>74.3</u></td>
      <td><u>81.1</u></td>
      <td>74.5</td>
      <td><u>70.6/75.2</u></td>
      <td><u>71.3/74.1</u></td>
      <td><u>72.7/74.0</u></td>
      <td>23.3/74.6</td>
      <td>73.6</td>
    </tr>
    <tr>
      <td>RapidTable</td>
      <td><strong>80.0</strong></td>
      <td><strong>83.2</strong></td>
      <td><strong>91.2</strong></td>
      <td><strong>83.0</strong></td>
      <td><strong>79.7</strong></td>
      <td><strong>83.4</strong></td>
      <td>78.4</td>
      <td><strong>77.1/85.4</strong></td>
      <td><strong>76.7/83.9</strong></td>
      <td><strong>77.6/84.9</strong></td>
      <td><u>25.2/83.7</u></td>
      <td><strong>82.5</strong></td>
    </tr>
    <tr>
      <td rowspan="2"><strong>Expert VLMs</strong></td>
      <td>StructEqTable</td>
      <td>72.0</td>
      <td>72.6</td>
      <td>81.7</td>
      <td>68.8</td>
      <td>64.3</td>
      <td>80.7</td>
      <td><strong>85.0</strong></td>
      <td>65.1/76.8</td>
      <td>69.4/73.5</td>
      <td>66.8/75.7</td>
      <td><strong>44.1/73.3</strong></td>
      <td>72.7</td>
    </tr>
    <tr>
      <td>GOT-OCR</td>
      <td>72.2</td>
      <td><u>75.5</u></td>
      <td><u>85.4</u></td>
      <td><u>73.1</u></td>
      <td>72.7</td>
      <td>78.2</td>
      <td>75.7</td>
      <td>65.0/80.2</td>
      <td>64.3/77.3</td>
      <td>70.8/76.9</td>
      <td>8.5/76.3</td>
      <td><u>74.9</u></td>
    </tr>
    <tr>
      <td rowspan="2"><strong>General VLMs</strong></td>
      <td>Qwen2-VL-7B</td>
      <td>70.2</td>
      <td>70.7</td>
      <td>82.4</td>
      <td>70.2</td>
      <td>62.8</td>
      <td>74.5</td>
      <td><u>80.3</u></td>
      <td>60.8/76.5</td>
      <td>63.8/72.6</td>
      <td>71.4/70.8</td>
      <td>20.0/72.1</td>
      <td>71.0</td>
    </tr>
    <tr>
      <td>InternVL2-8B</td>
      <td>70.9</td>
      <td>71.5</td>
      <td>77.4</td>
      <td>69.5</td>
      <td>69.2</td>
      <td>74.8</td>
      <td>75.8</td>
      <td>58.7/78.4</td>
      <td>62.4/73.6</td>
      <td>68.2/73.1</td>
      <td>20.4/72.6</td>
      <td>71.5</td>
    </tr>
  </tbody>
</table>
<p>Component-level Table Recognition evaluation on OmniDocBench table subset. <i>(+/-)</i> means <i>with/without</i> special situation.</p>


è¡¨æ ¼è¯†åˆ«è¯„æµ‹å¯ä»¥å‚è€ƒ[table_recognition](./configs/table_recognition.yaml)è¿›è¡Œé…ç½®ã€‚ 

**å¯¹äºæ¨¡å‹é¢„æµ‹ä¸ºLaTexæ ¼å¼çš„è¡¨æ ¼, ä¼šä½¿ç”¨[latexml](https://math.nist.gov/~BMiller/LaTeXML/)å·¥å…·å°†latexè½¬ä¸ºhtml å†è¿›è¡Œè¯„æµ‹. è¯„æµ‹ä»£ç ä¼šè‡ªåŠ¨è¿›è¡Œæ ¼å¼è½¬æ¢,éœ€è¦ç”¨æˆ·é¢„å…ˆå®‰è£…[latexml](https://math.nist.gov/~BMiller/LaTeXML/)**

<details>
  <summary>table_recognition.yamlçš„å­—æ®µè§£é‡Š</summary>

`table_recognition.yaml`çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```YAML
recogition_eval:      # æŒ‡å®štaskåç§°ï¼Œæ‰€æœ‰çš„è¯†åˆ«ç›¸å…³çš„ä»»åŠ¡é€šç”¨æ­¤task
  metrics:            # é…ç½®éœ€è¦ä½¿ç”¨çš„metric
    - TEDS            # Tree Edit Distance based Similarity
    - Edit_dist       # Normalized Edit Distance
  dataset:                                                                   # æ•°æ®é›†é…ç½®
    dataset_name: omnidocbench_single_module_dataset                         # æ•°æ®é›†åç§°ï¼Œå¦‚æœæŒ‰ç…§è§„å®šçš„è¾“å…¥æ ¼å¼åˆ™ä¸éœ€è¦ä¿®æ”¹
    ground_truth:                                                            # é’ˆå¯¹ground truthçš„æ•°æ®é›†é…ç½®
      data_path: ./demo_data/recognition/OmniDocBench_demo_table.json        # åŒæ—¶åŒ…å«ground truthå’Œæ¨¡å‹predictionç»“æœçš„JSONæ–‡ä»¶
      data_key: html                                                         # å­˜å‚¨Ground Truthçš„å­—æ®µåï¼Œå¯¹äºOmniDocBenchæ¥è¯´ï¼Œè¡¨æ ¼çš„è¯†åˆ«ç»“æœå­˜å‚¨åœ¨htmlå’Œlatexä¸¤ä¸ªå­—æ®µä¸­, è¯„æµ‹latexæ ¼å¼è¡¨æ ¼æ—¶æ”¹ä¸ºlatex
      category_filter: table                                                 # ç”¨äºè¯„æµ‹çš„ç±»åˆ«ï¼Œåœ¨è¡¨æ ¼è¯†åˆ«ä¸­ï¼Œè¯„æµ‹çš„category_nameæ˜¯table
    prediction:                                                              # é’ˆå¯¹æ¨¡å‹é¢„æµ‹ç»“æœçš„é…ç½®
      data_key: pred                                                         # å­˜å‚¨æ¨¡å‹é¢„æµ‹ç»“æœçš„å­—æ®µåï¼Œè¿™ä¸ªæ˜¯ç”¨æˆ·è‡ªå®šä¹‰çš„
    category_type: table                                                     # category_typeä¸»è¦æ˜¯ç”¨äºæ•°æ®é¢„å¤„ç†ç­–ç•¥çš„é€‰æ‹©
```

`dataset`çš„éƒ¨åˆ†ï¼Œè¾“å…¥çš„`ground_truth`çš„`data_path`ä¸­çš„æ•°æ®æ ¼å¼ä¸OmniDocBenchä¿æŒä¸€è‡´ï¼Œä»…å¯¹åº”çš„è¡¨æ ¼sampleä¸‹æ–°å¢ä¸€ä¸ªè‡ªå®šä¹‰å­—æ®µä¿å­˜æ¨¡å‹çš„predictionç»“æœã€‚é€šè¿‡`dataset`ä¸‹çš„`prediction`å­—æ®µä¸‹çš„`data_key`å¯¹å­˜å‚¨äº†predictionä¿¡æ¯çš„å­—æ®µè¿›è¡ŒæŒ‡å®šï¼Œæ¯”å¦‚`pred`ã€‚å…³äºæ›´å¤šOmniDocBenchçš„æ–‡ä»¶ç»“æ„ç»†èŠ‚è¯·å‚è€ƒ`è¯„æµ‹é›†ä»‹ç»`å°èŠ‚ã€‚æ¨¡å‹ç»“æœçš„è¾“å…¥æ ¼å¼å¯ä»¥å‚è€ƒ[OmniDocBench_demo_table](./demo_data/recognition/OmniDocBench_demo_table.json)ï¼Œå…¶æ ¼å¼ä¸ºï¼š

```JSON
[{
    "layout_dets": [    // é¡µé¢å…ƒç´ åˆ—è¡¨
        {
            "category_type": "table",  // OmniDocBenchç±»åˆ«åç§°
            "poly": [    // OmniDocBenchä½ç½®ä¿¡æ¯ï¼Œåˆ†åˆ«æ˜¯å·¦ä¸Šè§’ã€å³ä¸Šè§’ã€å³ä¸‹è§’ã€å·¦ä¸‹è§’çš„x,yåæ ‡
                136.0, 
                781.0,
                340.0,
                781.0,
                340.0,
                806.0,
                136.0,
                806.0
            ],
            ...   // å…¶ä»–OmniDocBenchå­—æ®µ
            "latex": "$xxx$",  // tableçš„LaTeXæ ‡æ³¨ä¼šå†™åœ¨è¿™é‡Œ
            "html": "$xxx$",  // tableçš„HTMLæ ‡æ³¨ä¼šå†™åœ¨è¿™é‡Œ
            "pred": "$xxx$",   // !! æ¨¡å‹çš„predictionç»“æœå­˜å‚¨åœ¨è¿™é‡Œï¼Œç”±ç”¨æˆ·è‡ªå®šä¹‰ä¸€ä¸ªæ–°å¢å­—æ®µï¼Œå­˜å‚¨åœ¨ä¸ground truthåŒçº§
            
        ...
    ],
    "page_info": {...},        // OmniDocBenché¡µé¢ä¿¡æ¯
    "extra": {...}             // OmniDocBenchæ ‡æ³¨é—´å…³ç³»ä¿¡æ¯
},
...
]
```

åœ¨æ­¤æä¾›ä¸€ä¸ªæ¨¡å‹inferçš„è„šæœ¬ä¾›å‚è€ƒï¼š

```PYTHON
import os
import json
from PIL import Image

def poly2bbox(poly):
    L = poly[0]
    U = poly[1]
    R = poly[2]
    D = poly[5]
    L, R = min(L, R), max(L, R)
    U, D = min(U, D), max(U, D)
    bbox = [L, U, R, D]
    return bbox

question = "<image>\nPlease convert this cropped image directly into html format of table."

with open('./demo_data/omnidocbench_demo/OmniDocBench_demo.json', 'r') as f:
    samples = json.load(f)
    
for sample in samples:
    img_name = os.path.basename(sample['page_info']['image_path'])
    img_path = os.path.join('./demo_data/omnidocbench_demo/images', img_name)
    img = Image.open(img_path)

    if not os.path.exists(img_path):
        print('No exist: ', img_name)
        continue

    for i, anno in enumerate(sample['layout_dets']):
        if anno['category_type'] != 'table':   # ç­›é€‰å‡ºè¡¨æ ¼ç±»åˆ«è¿›è¡Œè¯„æµ‹
            continue

        bbox = poly2bbox(anno['poly'])
        im = img.crop(bbox).convert('RGB')
        response = model.chat(im, question)  # éœ€è¦æ ¹æ®æ¨¡å‹ä¿®æ”¹ä¼ å…¥å›¾ç‰‡çš„æ–¹å¼
        anno['pred'] = response              # ç›´æ¥åœ¨å¯¹åº”çš„annotationä¸‹æ–°å¢å­—æ®µå­˜å‚¨æ¨¡å‹çš„inferç»“æœ

with open('./demo_data/recognition/OmniDocBench_demo_table.json', 'w', encoding='utf-8') as f:
    json.dump(samples, f, ensure_ascii=False)
```

</details>


### Layoutæ£€æµ‹

OmniDocBenchåŒ…å«æ¯ä¸ªPDFé¡µé¢çš„æ‰€æœ‰æ–‡æ¡£ç»„ä»¶çš„bounding boxä¿¡æ¯ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºLayoutæ£€æµ‹ä»»åŠ¡è¯„æµ‹çš„benchmarkã€‚

<table style="width: 90%; margin: auto; border-collapse: collapse;">
  <caption>Component-level layout detection evaluation on OmniDocBench layout subset: mAP results by PDF page type.</caption>
  <thead>
    <tr>
      <th style="border-bottom: 2px solid black;">Model</th>
      <th style="border-bottom: 2px solid black;">Book</th>
      <th style="border-bottom: 2px solid black;">Slides</th>
      <th style="border-bottom: 2px solid black;">Research Report</th>
      <th style="border-bottom: 2px solid black;">Textbook</th>
      <th style="border-bottom: 2px solid black;">Exam Paper</th>
      <th style="border-bottom: 2px solid black;">Magazine</th>
      <th style="border-bottom: 2px solid black;">Academic Literature</th>
      <th style="border-bottom: 2px solid black;">Notes</th>
      <th style="border-bottom: 2px solid black;">Newspaper</th>
      <th style="border-bottom: 2px solid black;">Average mAP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="border-top: 1px solid black;">DiT-L</td>
      <td style="border-top: 1px solid black; text-decoration: underline;">43.44</td>
      <td style="border-top: 1px solid black; text-decoration: underline;">13.72</td>
      <td style="border-top: 1px solid black; text-decoration: underline;">45.85</td>
      <td style="border-top: 1px solid black;">15.45</td>
      <td style="border-top: 1px solid black;">3.40</td>
      <td style="border-top: 1px solid black; text-decoration: underline;">29.23</td>
      <td style="border-top: 1px solid black; text-decoration: underline;">66.13</td>
      <td style="border-top: 1px solid black;">0.21</td>
      <td style="border-top: 1px solid black;">23.65</td>
      <td style="border-top: 1px solid black;">26.90</td>
    </tr>
    <tr>
      <td>LayoutLMv3</td>
      <td>42.12</td>
      <td>13.63</td>
      <td>43.22</td>
      <td style="text-decoration: underline;">21.00</td>
      <td>5.48</td>
      <td>31.81</td>
      <td>64.66</td>
      <td>0.80</td>
      <td style="text-decoration: underline;">30.84</td>
      <td style="text-decoration: underline;">28.84</td>
    </tr>
    <tr>
      <td>DOCX-Chain</td>
      <td>30.86</td>
      <td>11.71</td>
      <td>39.62</td>
      <td style="text-decoration: underline;">19.23</td>
      <td style="text-decoration: underline;">10.67</td>
      <td>23.00</td>
      <td>41.60</td>
      <td style="text-decoration: underline;">1.80</td>
      <td>16.96</td>
      <td>21.27</td>
    </tr>
    <tr>
      <td style="font-weight: bold;">DocLayout-YOLO</td>
      <td style="font-weight: bold;">43.71</td>
      <td style="font-weight: bold;">48.71</td>
      <td style="font-weight: bold;">72.83</td>
      <td style="font-weight: bold;">42.67</td>
      <td style="font-weight: bold;">35.40</td>
      <td style="font-weight: bold;">51.44</td>
      <td style="font-weight: bold;">66.84</td>
      <td style="font-weight: bold;">9.54</td>
      <td style="font-weight: bold;">57.54</td>
      <td style="font-weight: bold;">48.71</td>
    </tr>
  </tbody>
</table>


Layoutæ£€æµ‹configæ–‡ä»¶å‚è€ƒ[layout_detection](./configs/layout_detection.yaml)ï¼Œæ•°æ®æ ¼å¼å‚è€ƒ[detection_prediction](./demo_data/detection/detection_prediction.json)ã€‚

<details>
  <summary>layout_detection.yamlçš„å­—æ®µè§£é‡Š</summary>

ä»¥ä¸‹æˆ‘ä»¬ä»¥ç²¾ç®€æ ¼å¼ä¸ºä¾‹è¿›è¡Œå±•ç¤ºã€‚`layout_detection.yaml`çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```YAML
detection_eval:   # æŒ‡å®štaskåç§°ï¼Œæ‰€æœ‰çš„æ£€æµ‹ç›¸å…³çš„ä»»åŠ¡é€šç”¨æ­¤task
  metrics:
    - COCODet     # æ£€æµ‹ä»»åŠ¡ç›¸å…³æŒ‡æ ‡ï¼Œä¸»è¦æ˜¯mAP, mARç­‰
  dataset: 
    dataset_name: detection_dataset_simple_format       # æ•°æ®é›†åç§°ï¼Œå¦‚æœæŒ‰ç…§è§„å®šçš„è¾“å…¥æ ¼å¼åˆ™ä¸éœ€è¦ä¿®æ”¹
    ground_truth:
      data_path: ./demo_data/omnidocbench_demo/OmniDocBench_demo.json               # OmniDocBenchçš„JSONæ–‡ä»¶è·¯å¾„
    prediction:
      data_path: ./demo_data/detection/detection_prediction.json                    # æ¨¡å‹é¢„æµ‹ç»“æœJSONæ–‡ä»¶è·¯å¾„
    filter:                                             # é¡µé¢çº§åˆ«çš„ç­›é€‰
      data_source: exam_paper                           # éœ€è¦è¯„æµ‹çš„é¡µé¢å±æ€§ä»¥åŠå¯¹åº”æ ‡ç­¾
  categories:
    eval_cat:                # å‚ä¸æœ€ç»ˆè¯„æµ‹çš„ç±»åˆ«
      block_level:           # blockçº§åˆ«çš„ç±»åˆ«ï¼Œè¯¦ç»†ç±»åˆ«ä¿¡æ¯è¯·å‚è€ƒOmniDocBenchçš„è¯„æµ‹é›†ä»‹ç»éƒ¨åˆ†
        - title              # Title
        - text               # Text
        - abandon            # Includes headers, footers, page numbers, and page annotations
        - figure             # Image
        - figure_caption     # Image caption
        - table              # Table
        - table_caption      # Table caption
        - table_footnote     # Table footnote
        - isolate_formula    # Display formula (this is a layout display formula, lower priority than 14)
        - formula_caption    # Display formula label
    gt_cat_mapping:          # ground truthåˆ°æœ€ç»ˆè¯„æµ‹ç±»åˆ«çš„æ˜ å°„è¡¨ï¼Œkeyæ˜¯ground truthç±»åˆ«ï¼Œvalueæ˜¯æœ€ç»ˆè¯„æµ‹ç±»åˆ«åç§°
      figure_footnote: figure_footnote
      figure_caption: figure_caption 
      page_number: abandon 
      header: abandon 
      page_footnote: abandon
      table_footnote: table_footnote 
      code_txt: figure 
      equation_caption: formula_caption 
      equation_isolated: isolate_formula
      table: table 
      refernece: text 
      table_caption: table_caption 
      figure: figure 
      title: title 
      text_block: text 
      footer: abandon
    pred_cat_mapping:       # predictionåˆ°æœ€ç»ˆè¯„æµ‹ç±»åˆ«çš„æ˜ å°„è¡¨ï¼Œkeyæ˜¯predictionç±»åˆ«ï¼Œvalueæ˜¯æœ€ç»ˆè¯„æµ‹ç±»åˆ«åç§°
      title : title
      plain text: text
      abandon: abandon
      figure: figure
      figure_caption: figure_caption
      table: table
      table_caption: table_caption
      table_footnote: table_footnote
      isolate_formula: isolate_formula
      formula_caption: formula_caption
```

ä½¿ç”¨filterå­—æ®µå¯ä»¥å¯¹æ•°æ®é›†è¿›è¡Œç­›é€‰ï¼Œæ¯”å¦‚å°†`dataset`ä¸‹è®¾ç½®`filter`å­—æ®µä¸º`data_source: exam_paper`å³ç­›é€‰æ•°æ®ç±»å‹ä¸ºexam_paperçš„é¡µé¢ã€‚æ›´å¤šé¡µé¢å±æ€§è¯·å‚è€ƒâ€œè¯„æµ‹é›†ä»‹ç»â€éƒ¨åˆ†ã€‚å¦‚æœå¸Œæœ›å…¨é‡è¯„æµ‹ï¼Œè¯·æ³¨é‡Šæ‰`filter`ç›¸å…³å­—æ®µã€‚

`dataset`éƒ¨åˆ†`prediction`çš„`data_path`ä¸­ä¼ å…¥çš„æ˜¯æ¨¡å‹çš„predictionï¼Œå…¶æ•°æ®æ ¼å¼ä¸ºï¼š

```JSON
{
    "results": [
        {
            "image_name": "docstructbench_llm-raw-scihub-o.O-adsc.201190003.pdf_6",                     // å›¾ç‰‡å
            "bbox": [53.892921447753906, 909.8675537109375, 808.5555419921875, 1006.2714233398438],     // bounding boxä¿¡æ¯ï¼Œåˆ†åˆ«æ˜¯å·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„x,yåæ ‡
            "category_id": 1,                                                                           // ç±»åˆ«åºå·åç§°
            "score": 0.9446213841438293                                                                 // ç½®ä¿¡åº¦
        }, 
        ...                                                                                             // æ‰€æœ‰çš„bounding boxéƒ½ç›´æ¥å¹³é“ºåœ¨ä¸€ä¸ªlistå†…éƒ¨
    ],
    "categories": {"0": "title", "1": "plain text", "2": "abandon", ...}                                // æ¯ä¸ªç±»åˆ«åºå·æ‰€å¯¹åº”çš„ç±»åˆ«åç§°
```

</details>

### å…¬å¼æ£€æµ‹

OmniDocBenchåŒ…å«æ¯ä¸ªPDFé¡µé¢çš„å…¬å¼çš„bounding boxä¿¡æ¯ï¼Œå› æ­¤å¯ä»¥ä½œä¸ºLayoutæ£€æµ‹ä»»åŠ¡è¯„æµ‹çš„benchmarkã€‚

<table style="width: 47%;">
  <thead>
    <tr>
      <th>Models</th>
      <th>CDM</th>
      <th>ExpRate@CDM</th>
      <th>BLEU</th>
      <th>Norm Edit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GOT-OCR</td>
      <td>74.1</td>
      <td>28.0</td>
      <td>55.07</td>
      <td>0.290</td>
    </tr>
    <tr>
      <td>Mathpix</td>
      <td><u>86.6</u></td>
      <td>2.8</td>
      <td><b>66.56</b></td>
      <td>0.322</td>
    </tr>
    <tr>
      <td>Pix2Tex</td>
      <td>73.9</td>
      <td>39.5</td>
      <td>46.00</td>
      <td>0.337</td>
    </tr>
    <tr>
      <td>UniMERNet-B</td>
      <td>85.0</td>
      <td><u>60.2</u></td>
      <td><u>60.84</u></td>
      <td><b>0.238</b></td>
    </tr>
    <tr>
      <td>GPT4o</td>
      <td><b>86.8</b></td>
      <td><b>65.5</b></td>
      <td>45.17</td>
      <td><u>0.282</u></td>
    </tr>
    <tr>
      <td>InternVL2-Llama3-76B</td>
      <td>67.4</td>
      <td>54.5</td>
      <td>47.63</td>
      <td>0.308</td>
    </tr>
    <tr>
      <td>Qwen2-VL-72B</td>
      <td>83.8</td>
      <td>55.4</td>
      <td>53.71</td>
      <td>0.285</td>
    </tr>
  </tbody>
</table>
<p>Component-level formula recognition evaluation on OmniDocBench formula subset.</p>


å…¬å¼æ£€æµ‹ä¸Layoutæ£€æµ‹çš„æ ¼å¼åŸºæœ¬ä¸€è‡´ã€‚å…¬å¼åŒ…å«è¡Œå†…å…¬å¼å’Œè¡Œé—´å…¬å¼ã€‚åœ¨æœ¬èŠ‚æä¾›ä¸€ä¸ªconfigæ ·ä¾‹ï¼Œå¯ä»¥åŒæ—¶è¯„æµ‹è¡Œé—´å…¬å¼å’Œè¡Œå†…å…¬å¼çš„æ£€æµ‹ç»“æœã€‚å…¬å¼æ£€æµ‹å¯ä»¥å‚è€ƒ[formula_detection](./configs/formula_detection.yaml)è¿›è¡Œé…ç½®ã€‚

<details>
  <summary>formula_detection.yamlçš„å­—æ®µè§£é‡Š</summary>

`formula_detection.yaml`çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```YAML
detection_eval:   # æŒ‡å®štaskåç§°ï¼Œæ‰€æœ‰çš„æ£€æµ‹ç›¸å…³çš„ä»»åŠ¡é€šç”¨æ­¤task
  metrics:
    - COCODet     # æ£€æµ‹ä»»åŠ¡ç›¸å…³æŒ‡æ ‡ï¼Œä¸»è¦æ˜¯mAP, mARç­‰
  dataset: 
    dataset_name: detection_dataset_simple_format       # æ•°æ®é›†åç§°ï¼Œå¦‚æœæŒ‰ç…§è§„å®šçš„è¾“å…¥æ ¼å¼åˆ™ä¸éœ€è¦ä¿®æ”¹
    ground_truth:
      data_path: ./demo_data/omnidocbench_demo/OmniDocBench_demo.json               # OmniDocBenchçš„JSONæ–‡ä»¶è·¯å¾„
    prediction:
      data_path: ./demo_data/detection/detection_prediction.json                     # æ¨¡å‹é¢„æµ‹ç»“æœJSONæ–‡ä»¶è·¯å¾„
    filter:                                             # é¡µé¢çº§åˆ«çš„ç­›é€‰
      data_source: exam_paper                           # éœ€è¦è¯„æµ‹çš„é¡µé¢å±æ€§ä»¥åŠå¯¹åº”æ ‡ç­¾
  categories:
    eval_cat:                                  # å‚ä¸æœ€ç»ˆè¯„æµ‹çš„ç±»åˆ«
      block_level:                             # blockçº§åˆ«çš„ç±»åˆ«ï¼Œè¯¦ç»†ç±»åˆ«ä¿¡æ¯è¯·å‚è€ƒOmniDocBenchçš„è¯„æµ‹é›†ä»‹ç»éƒ¨åˆ†
        - isolate_formula                      # è¡Œé—´å…¬å¼
      span_level:                              # spançº§åˆ«çš„ç±»åˆ«ï¼Œè¯¦ç»†ç±»åˆ«ä¿¡æ¯è¯·å‚è€ƒOmniDocBenchçš„è¯„æµ‹é›†ä»‹ç»éƒ¨åˆ†
        - inline_formula                       # è¡Œå†…å…¬å¼
    gt_cat_mapping:                            # ground truthåˆ°æœ€ç»ˆè¯„æµ‹ç±»åˆ«çš„æ˜ å°„è¡¨ï¼Œkeyæ˜¯ground truthç±»åˆ«ï¼Œvalueæ˜¯æœ€ç»ˆè¯„æµ‹ç±»åˆ«åç§°
      equation_isolated: isolate_formula
      equation_inline: inline_formula
    pred_cat_mapping:                          # predictionåˆ°æœ€ç»ˆè¯„æµ‹ç±»åˆ«çš„æ˜ å°„è¡¨ï¼Œkeyæ˜¯predictionç±»åˆ«ï¼Œvalueæ˜¯æœ€ç»ˆè¯„æµ‹ç±»åˆ«åç§°
      interline_formula: isolate_formula
      inline_formula: inline_formula
```

configä¸­å‚æ•°è§£é‡Šä»¥åŠæ•°æ®é›†æ ¼å¼è¯·å‚è€ƒ`Layoutæ£€æµ‹`å°èŠ‚ï¼Œå…¬å¼æ£€æµ‹ä¸Layoutæ£€æµ‹å°èŠ‚çš„ä¸»è¦åŒºåˆ«æ˜¯ï¼Œåœ¨å‚ä¸æœ€ç»ˆè¯„æµ‹çš„ç±»åˆ«`eval_cat`ä¸‹æ–°å¢äº†`span_level`çš„ç±»åˆ«`inline_formula`ï¼Œspan_levelçš„ç±»åˆ«å’Œblock_levelçº§åˆ«çš„ç±»åˆ«åœ¨è¯„æµ‹çš„æ—¶å€™å°†ä¼šå…±åŒå‚ä¸è¯„æµ‹ã€‚

</details>

## Tools

æˆ‘ä»¬åœ¨`tools`ç›®å½•ä¸‹æä¾›äº†ä¸€äº›å·¥å…·ï¼š
- [json2md](./tools/json2md.py) ç”¨äºå°†JSONæ ¼å¼çš„OmniDocBenchè½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼›
- [visualization](./tools/visualization.py) ç”¨äºå¯è§†åŒ–OmniDocBenchçš„JSONæ–‡ä»¶ï¼›
- [model_infer](./tools/model_infer)æ–‡ä»¶å¤¹ä¸‹æä¾›äº†ä¸€äº›æ¨¡å‹æ¨ç†çš„è„šæœ¬ä¾›å‚è€ƒï¼ŒåŒ…æ‹¬ï¼š
  - [mathpix_img2md.py](./tools/model_infer/mathpix_img2md.py) ç”¨äºè°ƒç”¨[mathpix](https://mathpix.com/)çš„APIå°†å›¾ç‰‡è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼›
  - [internvl2_test_img2md.py](./tools/model_infer/internvl2_test_img2md.py) ç”¨äºè°ƒç”¨[InternVL2](https://github.com/OpenGVLab/InternVL)æ¨¡å‹å°†å›¾ç‰‡è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œè¯·åœ¨é…ç½®äº†InternVL2æ¨¡å‹ç¯å¢ƒåä½¿ç”¨ï¼›
  - [GOT_img2md.py](./tools/model_infer/GOT_img2md.py) ç”¨äºè°ƒç”¨[GOT-OCR](https://github.com/Ucas-HaoranWei/GOT-OCR2.0)æ¨¡å‹å°†å›¾ç‰‡è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œè¯·åœ¨é…ç½®äº†GOT-OCRæ¨¡å‹ç¯å¢ƒåä½¿ç”¨ï¼›
  - [Qwen2VL_img2md.py](./tools/model_infer/Qwen2VL_img2md.py) ç”¨äºè°ƒç”¨[QwenVL](https://github.com/QwenLM/Qwen2-VL)æ¨¡å‹å°†å›¾ç‰‡è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œè¯·åœ¨é…ç½®äº†QwenVLæ¨¡å‹ç¯å¢ƒåä½¿ç”¨ï¼›

## TODO

- [ ] åŒ¹é…ç®—æ³•`match_full`æ¥å…¥
- [ ] é’ˆå¯¹æ¨¡å‹ç‰¹å®šè¾“å‡ºæ ¼å¼è¿›è¡ŒåŒ¹é…åå¤„ç†ä¼˜åŒ–
- [ ] å¢åŠ ç‰¹æ®Šå­—ç¬¦çš„Unicodeæ˜ å°„è¡¨

## Known Issues

- éƒ¨åˆ†æ¨¡å‹å¶å°”ä¼šå‡ºç°è¾“å‡ºæ ¼å¼ä¸è§„èŒƒï¼ˆæ¯”å¦‚å°†å¤šæ æ–‡æœ¬è¯†åˆ«ä¸ºè¡¨æ ¼ï¼Œå°†å…¬å¼è¯†åˆ«ä¸ºUnicodeæ–‡æœ¬ï¼‰ï¼Œå¯¼è‡´åŒ¹é…å¤±è´¥çš„æƒ…å†µï¼Œå¯ä»¥é’ˆå¯¹æ¨¡å‹è¾“å‡ºæ ¼å¼è¿›è¡Œåå¤„ç†ä¼˜åŒ–
- ç”±äºå„ç§æ¨¡å‹å¯¹ç¬¦å·çš„è¯†åˆ«èƒ½åŠ›ä¸åŒï¼Œå¯¼è‡´éƒ¨åˆ†ç¬¦å·çš„è¯†åˆ«ç»“æœä¸ä¸€è‡´ï¼ˆæ¯”å¦‚åˆ—è¡¨çš„æ ‡è¯†ç¬¦ç­‰ï¼‰ï¼Œç›®å‰çš„æ–‡æœ¬è¯„æµ‹ä¸­ä»…ä¿ç•™ä¸­è‹±æ–‡æœ¬å‚ä¸è¯„æµ‹ï¼Œåç»­å°†å¢åŠ Unicodeæ˜ å°„è¡¨æ¥ä¼˜åŒ–

æ¬¢è¿å¤§å®¶ä½¿ç”¨OmniDocBenchæ•°æ®é›†ï¼Œå¹¶æå‡ºå®è´µçš„æ„è§å’Œå»ºè®®ï¼Œå¸®åŠ©æˆ‘ä»¬ä¸æ–­ä¼˜åŒ–æ•°æ®é›†è´¨é‡å’Œè¯„æµ‹å·¥å…·ã€‚æœ‰ä»»ä½•æ„è§å’Œå»ºè®®ï¼Œæ¬¢è¿æissueï¼Œæˆ‘ä»¬å°†åœ¨ç¬¬ä¸€æ—¶é—´å“åº”ã€‚å¦‚æœ‰è¯„æµ‹æ–¹æ¡ˆä¼˜åŒ–å¯ä»¥æPRï¼Œæˆ‘ä»¬ä¹Ÿå°†åŠæ—¶reviewå’Œæ›´æ–°ã€‚

## Acknowledgement

- æ„Ÿè°¢[Abaka AI](https://abaka.ai)æä¾›çš„é«˜è´¨é‡æ•°æ®é›†æ ‡æ³¨
- [PubTabNet](https://github.com/ibm-aur-nlp/PubTabNet) TEDSæŒ‡æ ‡è®¡ç®—
- [latexml](https://github.com/brucemiller/LaTeXML) LaTeX to HTMLè½¬æ¢å·¥å…·
- [Tester](https://github.com/intsig-textin/markdown_tester) Markdownè¡¨æ ¼è½¬HTMLå·¥å…·

## ç‰ˆæƒå£°æ˜
  
PDFæ¥æºä»ç½‘ç»œå…¬å¼€æ¸ é“æ”¶é›†ä»¥åŠç¤¾ç¾¤ç”¨æˆ·è´¡çŒ®ï¼Œå·²å‰”é™¤äº†ä¸å…è®¸åˆ†å‘çš„å†…å®¹ï¼Œåªç”¨ä½œç§‘ç ”ï¼Œä¸ä½œä¸ºå•†ä¸šç”¨é€”ã€‚è‹¥æœ‰ä¾µæƒè¯·è”ç³»OpenDataLab@pjlab.org.cnã€‚


## å¼•ç”¨

```bibtex
@misc{ouyang2024omnidocbench,
  title={OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations},
  author={Linke Ouyang and Yuan Qu and Hongbin Zhou and Jiawei Zhu and Rui Zhang and Qunshu Lin and Bin Wang and Zhiyuan Zhao and Man Jiang and Xiaomeng Zhao and Jin Shi and Fan Wu and Pei Chu and Minghao Liu and Zhenxiang Li and Chao Xu and Bo Zhang and Botian Shi and Zhongying Tu and Conghui He},
  year={2024},
  note={To appear on arXiv},
}
```